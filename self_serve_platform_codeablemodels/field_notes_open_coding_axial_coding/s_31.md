# s 
31
## url
https://medium.com/slalom-data-ai/data-mesh-232e50f42e66
## tiny url
https://tinyurl.com/self-serve-platform-s31
## archive url
https://bit.ly/self-serve-platform-s31
## title
Deconstructing Data Mesh Principles
## source code
no
## example
yes
## source type 
Practitioner Audience Article
## author type
Practitioner
## references

**AXIAL CODING TRACE:**
``` python
s31 = CClass(source, "s31", values={
    "title": "Deconstructing Data Mesh Principles",
    "url": "https://medium.com/slalom-data-ai/data-mesh-232e50f42e66",
    "archive url": "https://bit.ly/self-serve-platform-s31",
    "tiny url": "https://tinyurl.com/self-serve-platform-s31",
    "author type": "Practitioner",
    "type": "Practitioner Audience Article",
    "example": True,
    "source code": False})
```

# coding

> Deconstructing Data Mesh Principles

> Principle 3: Self-serve data infrastructure as a platform

> The data as a product concept raises concerns regarding the cost of ownership for the domain team, leading to the third data mesh principle: self-serve data infrastructure as a platform. The intent of this principle is to develop a set of solution building blocks we’re terming as infrastructure abstractions that can be combined and leveraged to accelerate the build of producers in the mesh.
This approach also helps with standardisation of tools and patterns across data domains.
The key to building the data infrastructure as a platform is to:
Keep it domain agnostic.
Make sure the platform hides underlying complexities and provides data infrastructure components in a self-service manner.
Lower the lead time to create a new data product on the infrastructure.

![InfrastructurePlatform](https://miro.medium.com/v2/resize:fit:720/format:webp/1*N4fG2HxqlOLKNFswyS0VzA.png)

**OPEN CODING TRACE:**

access_control_management

dependable_pipeline_management

infrastructure_as_code

log_management

data_transformation_orchestration

register_derived_data_as_data_product

separating_storage_and_compute

version_dp

VNetPeering

**AXIAL CODING TRACE:**
added:
``` python
    
    access_control_management
    dependable_pipeline_management
    infrastructure_as_code
    log_management
    data_transformation_orchestration
    polygot_storage_option
    register_derived_data_as_data_product
    separating_storage_and_compute
    version_dp
    VNetPeering
    
```

> Platform abstractions can take the form of scalable polyglot storage, federated identify management, or data pipeline orchestration. In essence, any capability that would be shared across producers is in scope for being abstracted.
The abstraction of these platform components gives rise to a data infrastructure platform, offering trusted, secure, and reliable infrastructure abstractions that can be combined to build the producers in the mesh.

> Operating model impacts
The benefits of creating platform abstractions in the form of re-usable infrastructure patterns is two-fold: it reduces the burden of developing a data product while avoiding the risk of proliferating complexity in the environment. This ensures the overall mesh remains manageable within the organisation.
All signs point to the establishment of a shared platform team that is responsible for developing these building blocks and owning the overall platform. Much like the data domain teams build data products for the business, the shared platform team should build platform abstractions for the data domain teams. In this way, the data domain teams may be considered the customer of the shared platform team.
Nonetheless, this doesn’t absolve the data domain teams from maintaining their data products. Instead, we would expect to see a shared responsibility model between these teams, with data domain teams responsible for some aspects of the solution (such as data quality, maintaining data models, and ingestion logic) and the shared platform team responsible for other aspects (including infrastructure monitoring, integration platforms, and solution templates).

**OPEN CODING TRACE:**

build_deploy_monitor_dp
integration_service
scalability
data_observability
delegated_ownership

data_governance_function

**AXIAL CODING TRACE:**
added:
``` python
    data_observability
    build_deploy_monitor_dp
    integration_service
    scalability
    delegated_ownership
    data_governance_function
```

![DomainTeam](https://miro.medium.com/v2/resize:fit:720/format:webp/1*Xy49fmX4ifHrh5uvqpdpYA.png)

> Additionally, the role of the shared platform team extends to components that are common to all producers in the mesh. This includes infrastructure monitoring, Identity Access Management (IAM), development pipelines, and shared product interface platforms (such as API interfaces). Having a centralised team develop and own these capabilities helps with standardisation and management of the mesh.
That said, experience with federated models shows that these teams are often poorly resourced and risk becoming a bottleneck for the organisation — the exact issue we’re trying to avoid. If we’re too restrictive and not strategic in our planning, data domain teams may end up waiting for shared platform teams to make a critical service available or go create a solution that is hard to manage and govern.
Therefore, when establishing this function, it’s worth considering the following:
Developing a shared platform strategy. Identify the MVP platform capabilities and develop these first before scaling the platform to address the rest of the data product team’s requirements.
Making sure the shared platform team operates with a product development mentality. This will direct focus to developing the right capabilities and ensure the appropriate level of ongoing support.
Developing an inner sourcing model. This enables data domain teams to develop their own infrastructure abstractions, contributing to a central repository and alleviating some of the pressure on the shared team. This can be incentivised through rewards and recognition programs.
Developing clear solution guidelines. This removes ambiguity around security, governance, and strategic tooling requirements as early as possible, enabling the shared platform team to focus on getting infrastructure abstractions in the hands of data domain teams.
Documenting a shared responsibility model. Development and ownership responsibilities of a data product should be clear to both the domain teams and the platform team. This not only helps avoid issues and allows for swift resolutions, but also ensures teams will be resourced with the right skills to perform their function.
Clearly defining a product release process. When a product is ready to be consumed, it needs to be integrated into the shared interface platforms. To avoid delays, a clear process for executing this integration should be defined, outlining each step, who will execute it, and in what timeframe.




















