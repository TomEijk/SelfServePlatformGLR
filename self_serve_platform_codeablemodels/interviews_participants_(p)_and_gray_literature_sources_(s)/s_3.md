# s 
3
## url
https://www.datamesh-architecture.com/
## tiny url
https://tinyurl.com/self-serve-plaform-s3
## archive url
https://tinyurl.com/self-serve-plaform-s3
## title
Data Mesh From an Engineering Perspective
## source code
no
## example
yes
## source type 
Practitioner Audience Article
## author type
Practitioner
## references

**AXIAL CODING TRACE:**
``` python
s3 = CClass(source, "s3", values={
    "title": "Data Mesh From an Engineering Perspective",
    "url": "https://www.datamesh-architecture.com/",
    "archive url": "https://tinyurl.com/self-serve-plaform-s3",
    "tiny url": "https://tinyurl.com/self-serve-plaform-s3",
    "author type": "Practitioner",
    "type": "Practitioner Audience Article",
    "example": True,
    "source code": False})
```

# coding

> Data Platform

> The self-serve data platform may vary for each organization. Data mesh is a new field and vendors are starting to add data mesh capabilities to their existing offerings.

> Looking from the desired capabilities, you can distinguish between analytical capabilities and data product capabilities: Analytical capabilities enable the domain team to build an analytical data model and perform analytics for data-driven decisions. The data platform needs functions to ingest, store, query, and visualize data as a self-service. Typical data warehouse and data lake solutions, whether on-premise or a cloud provider, already exist. The major difference is that each domain team gets its own isolated area.

> A more advanced data platform for data mesh also provides additional domain-agnostic data product capabilities for creating, monitoring, discovering, and accessing data products. The self-serve data platform should support the domain teams so that they can quickly build a data product as well as run it in production in their isolated area. The platform should support the domain team in publishing their data products so that other teams can discover them. The discovery requires a central entry point for all the decentralized data products. A data catalog can be implemented in different ways: as a wiki, git repository, or there are even already vendor solutions for a cloud-based data catalog such as Select Star, Google Data Catalog, or AWS Glue Data Catalog. The actual usage of data products, however, requires a domain team to access, integrate, and query other domains' data products. The platform should support, monitor, and document the cross-domain access and usage of data products.

> An even more advanced data platform supports policy automation. This means that, instead of forcing the domain team to manually ensure that the global policies are not violated, the policies are automatically enforced through the platform. For example, that all data products have the same metadata structure in the data catalog, or that the PII data are automatically removed during data ingestion.

> Efficiently combining data products from multiple domains, i.e., having large cross-domain join operations within a few seconds, ensures developer acceptance and happiness. That's why the query engine has a large influence on the architecture of the data platform. A shared platform with a single query language and support for separated areas is a good way to start as everything is highly integrated. This could be Google BigQuery with tables in multiple projects that are discoverable through Google Data Catalog. In a more decentralized and distributed data mesh, a distributed query engine such as Presto can still perform cross-domain joins without importing data, but they come with their own limitations, e.g., limited pushdowns require that all underlying column data need to be transferred.

**OPEN CODING TRACE:**

A platform to ingest data from data sources into an analytics infrastructure without requiring any code

Distributed file storage

Query function

Storage function

Visualization function 

Access Control Management 

Centrally govern data across domains while enabling autonomous and delegated ownership of data

Provides the ability to manage reader/writer permissions on the domains 

Easily search, browse, discover + 

Query Engine

discoverability

discovery_and_explore_dps

**AXIAL CODING TRACE:**
added:
``` python
    
    build_deploy_monitor_dp
    data_source_ingestion = CClass(practice, "Data Source Ingestion")
    distributed_file_storage = CClass(pattern, " Distributed file storage")
    storage_function = CClass(practice, "Storage Function")
    access_control_management = CClass(practice, "Access control management")
    data_catalog
    visualization_function = CClass(practice, "Visualization Function")
    manage_read_write_permissions = CClass(practice, "Manage read write functions") 
    searchability = CClass(force, "Searchability")
    discoverability = CClass(force, "Discoverability")
    centrally_govern = CClass(practice, "Centrally govern data")
    policy_automation = CClass(pattern, "Policy Automation")
    query_engine = CClass(pattern, "Query Engine")
    discoverability
    discovery_and_explore_dps
    build_deploy_monitor_dp
    
```
